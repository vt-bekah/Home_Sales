# Home_Sales
Answer the following questions about home sales using SparkSQL:
* What is the average price for a four-bedroom house sold for each year? Round off your answer to two decimal places.
* What is the average price of a home for each year it was built that has three bedrooms and three bathrooms? Round off your answer to two decimal places.
* What is the average price of a home for each year that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet? Round off your answer to two decimal places.
* What is the "view" rating for homes costing more than or equal to $350,000? Determine the run time for this query, and round off your answer to two decimal places.

# Features
* Read data from an AWS S3 bucket into a dataframe
* Use SparkSQL to execute queries from a temporary view of the datafame
* Cache the temporary table and compare performance
* Use parquet to partition the data and compare performance
* Clean-up cache

# Results
* What is the average price for a four-bedroom house sold for each year? Round off your answer to two decimal places.

date_built|avg_price
:----------|---------:
2016|296050.24
2017|296576.69
2010|296800.75
2012|298233.42
2014|299073.89
2013|299999.39
2011| 302141.9
2015|307908.86

* What is the average price of a home for each year it was built that has three bedrooms and three bathrooms? Round off your answer to two decimal places.

date_built|avg_price
:----------|---------:
2015| 288770.3
2016|290555.07
2014|290852.27
2011|291117.47
2017|292676.79
2010|292859.62
2012|293683.19
2013|295962.27

* What is the average price of a home for each year that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet? Round off your answer to two decimal places.

date_built|avg_price
:----------|---------
2011|276553.81
2017|280317.58
2010|285010.22
2016| 293965.1
2015|297609.97
2014|298264.72
2013|303676.79
2012|307539.97

* What is the "view" rating for homes costing more than or equal to $350,000? Determine the run time for this query, and round off your answer to two decimal places.

avg_price|avg_view|sum_view|min_view|max_view
:---------|--------|--------|--------|--------:
473796.26|   32.26|  358937|       0|     100

### Performance
* Without caching and partitioning, the final query took 1.10s
*  With caching, the final query took 0.75s
* With parquet partitioning, the final query took 0.89s

Caching and parquet partitioning improve performance compared to doing neither of these. The query complexity and dataset size will dictate whether parquet partitioning or caching will be better.


# File Notes
* Home_Sales_colab.ipynb conatins the solution for the challenge instructions.
    

# References
* Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.
* Google Colab: https://research.google.com/colaboratory/faq.html
 

# Getting Started

## Prerequisites
This solution was completed using Google Colab so it requires a Google Account set up for running jupyter notebooks in Google Colab. Refer to Geek's for Geeks (https://www.geeksforgeeks.org/how-to-use-google-colab/) for getting started if necessary.

## Cloning Repo
$ git clone https://github.com/vt-bekah/Home_Sales.git

open Google Colab from your browser and upload Home_Sales_colab.ipynb

# Built With
* Python v3.10.11
* spark 3.5.0
* java jdk v17
* jupyter notebook v6.5.2
* jupyterlab v3.6.3
* conda v23.5.0




